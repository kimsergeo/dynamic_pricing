{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-21T19:30:25.049058Z",
     "start_time": "2025-08-21T19:30:24.130522Z"
    }
   },
   "source": [
    "from typing import List, Dict, Any, Tuple, Union, Optional\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging\n",
    "logging.basicConfig()\n",
    "logger = logging.getLogger(\"back_test\")\n",
    "logger.setLevel(logging.INFO)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## TASK 1",
   "id": "1637a799d8bd00ed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T19:30:25.065061Z",
     "start_time": "2025-08-21T19:30:25.058060Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from enum import Enum\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class BackTestAlgo(str, Enum):\n",
    "    epsilon_greedy_sum = \"epsilon_greedy_sum\"\n",
    "\n",
    "    @classmethod\n",
    "    def to_list(cls) -> List[str]:\n",
    "        return list(map(lambda c: c.value, cls))  # type: ignore\n",
    "\n",
    "\n",
    "class BackTestLevel(str, Enum):\n",
    "    group_1 = \"group_1\"\n",
    "    item_id = \"item_id\"\n",
    "    sku_id = \"sku_id\"\n",
    "\n",
    "    @classmethod\n",
    "    def to_list(cls) -> List[str]:\n",
    "        return list(map(lambda c: c.value, cls))  # type: ignore\n",
    "\n",
    "\n",
    "class BackTestMetric(str, Enum):\n",
    "    orders_num = \"orders_num\"  # выручка\n",
    "\n",
    "    @classmethod\n",
    "    def to_list(cls) -> List[str]:\n",
    "        return list(map(lambda c: c.value, cls))  # type: ignore\n"
   ],
   "id": "acd1e079faaa820a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T19:30:25.294613Z",
     "start_time": "2025-08-21T19:30:25.073061Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get A/B Test data\n",
    "ab_df = pd.read_parquet(\"./hm/simulated_data.parquet\")\n",
    "\n",
    "# Set relevant data type\n",
    "ab_df[\"ds\"] = ab_df[\"ds\"].astype(str)\n",
    "\n",
    "# Calculate margin\n",
    "ab_df[\"margin\"] = ab_df[\"markup\"] * ab_df[\"revenue\"]\n",
    "\n",
    "ab_df.head()"
   ],
   "id": "f412733ddbcb216",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      group_1      sku_id ab_test_id  markup  revenue  traffic  orders_num  \\\n",
       "0  group_1000  sku_100000  ab_100000    0.01  2539.41     0.05         1.0   \n",
       "1  group_1001  sku_100001  ab_100001    0.02  6057.44     0.05         3.0   \n",
       "2  group_1002  sku_100002  ab_100002    0.01   541.35     0.05         8.0   \n",
       "3  group_1002  sku_100003  ab_100003    0.06   697.70     0.05         0.0   \n",
       "4  group_1001  sku_100004  ab_100004    0.01  1413.99     0.05         0.0   \n",
       "\n",
       "         ds    margin  \n",
       "0  20231008   25.3941  \n",
       "1  20231008  121.1488  \n",
       "2  20231008    5.4135  \n",
       "3  20231008   41.8620  \n",
       "4  20231008   14.1399  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_1</th>\n",
       "      <th>sku_id</th>\n",
       "      <th>ab_test_id</th>\n",
       "      <th>markup</th>\n",
       "      <th>revenue</th>\n",
       "      <th>traffic</th>\n",
       "      <th>orders_num</th>\n",
       "      <th>ds</th>\n",
       "      <th>margin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>group_1000</td>\n",
       "      <td>sku_100000</td>\n",
       "      <td>ab_100000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2539.41</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20231008</td>\n",
       "      <td>25.3941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>group_1001</td>\n",
       "      <td>sku_100001</td>\n",
       "      <td>ab_100001</td>\n",
       "      <td>0.02</td>\n",
       "      <td>6057.44</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20231008</td>\n",
       "      <td>121.1488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>group_1002</td>\n",
       "      <td>sku_100002</td>\n",
       "      <td>ab_100002</td>\n",
       "      <td>0.01</td>\n",
       "      <td>541.35</td>\n",
       "      <td>0.05</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20231008</td>\n",
       "      <td>5.4135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>group_1002</td>\n",
       "      <td>sku_100003</td>\n",
       "      <td>ab_100003</td>\n",
       "      <td>0.06</td>\n",
       "      <td>697.70</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20231008</td>\n",
       "      <td>41.8620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>group_1001</td>\n",
       "      <td>sku_100004</td>\n",
       "      <td>ab_100004</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1413.99</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20231008</td>\n",
       "      <td>14.1399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T19:30:25.418849Z",
     "start_time": "2025-08-21T19:30:25.311612Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get algorithm data\n",
    "algo_1 = pd.read_parquet(\"./hm/algo/algo_1.parquet\")\n",
    "algo_2 = pd.read_parquet(\"./hm/algo/algo_2.parquet\")\n",
    "algo_3 = pd.read_parquet(\"./hm/algo/algo_3.parquet\")\n",
    "algo_4 = pd.read_parquet(\"./hm/algo/algo_4.parquet\")\n",
    "algo_5 = pd.read_parquet(\"./hm/algo/algo_5.parquet\")\n",
    "\n",
    "# Get A/B test data\n",
    "ab_df = pd.read_parquet(\"./hm/simulated_data.parquet\")"
   ],
   "id": "8e12550817bdffe2",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T19:30:25.560849Z",
     "start_time": "2025-08-21T19:30:25.474850Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set necessary column types\n",
    "ab_df = ab_df \\\n",
    "    .assign(ds = lambda x: x[\"ds\"].astype(str),\n",
    "            margin = lambda x: x[\"markup\"] * x[\"revenue\"])\n",
    "\n",
    "algo_1 = algo_1 \\\n",
    "    .assign(ds = lambda x: x[\"ds\"].astype(str)) \\\n",
    "    .rename(columns={\"markup\": \"algo_1_markup\"})\n",
    "\n",
    "algo_2 = algo_2 \\\n",
    "    .assign(ds = lambda x: x[\"ds\"].astype(str)) \\\n",
    "    .rename(columns={\"markup\": \"algo_2_markup\"})\n",
    "\n",
    "algo_3 = algo_3 \\\n",
    "    .assign(ds = lambda x: x[\"ds\"].astype(str)) \\\n",
    "    .rename(columns={\"markup\": \"algo_3_markup\"})\n",
    "\n",
    "algo_4 = algo_4 \\\n",
    "    .assign(ds = lambda x: x[\"ds\"].astype(str)) \\\n",
    "    .rename(columns={\"markup\": \"algo_4_markup\"})\n",
    "\n",
    "algo_5 = algo_5 \\\n",
    "    .assign(ds = lambda x: x[\"ds\"].astype(str)) \\\n",
    "    .rename(columns={\"markup\": \"algo_5_markup\"})"
   ],
   "id": "bb557d6ace8776ba",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T19:30:25.688850Z",
     "start_time": "2025-08-21T19:30:25.614851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get unique combinations of dates and groups (categories)\n",
    "ds_df = pd.DataFrame({\"ds\": ab_df[\"ds\"].unique().tolist()})\n",
    "group_df = ab_df[[\"group_1\"]].drop_duplicates()\n",
    "\n",
    "algo_sample = ds_df.join(group_df, how=\"cross\")\n",
    "\n",
    "algo_sample"
   ],
   "id": "313344b531dbc15c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           ds     group_1\n",
       "0    20231008  group_1000\n",
       "1    20231008  group_1001\n",
       "2    20231008  group_1002\n",
       "3    20231008  group_1003\n",
       "4    20231008  group_1004\n",
       "..        ...         ...\n",
       "541  20231021  group_1034\n",
       "542  20231021  group_1035\n",
       "543  20231021  group_1036\n",
       "544  20231021  group_1037\n",
       "545  20231021  group_1038\n",
       "\n",
       "[546 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>group_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20231008</td>\n",
       "      <td>group_1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20231008</td>\n",
       "      <td>group_1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20231008</td>\n",
       "      <td>group_1002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20231008</td>\n",
       "      <td>group_1003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20231008</td>\n",
       "      <td>group_1004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>20231021</td>\n",
       "      <td>group_1034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>20231021</td>\n",
       "      <td>group_1035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>20231021</td>\n",
       "      <td>group_1036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>20231021</td>\n",
       "      <td>group_1037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>20231021</td>\n",
       "      <td>group_1038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>546 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T19:30:25.766677Z",
     "start_time": "2025-08-21T19:30:25.740677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get all algorithms data in a single dataframe\n",
    "algo_joint = algo_sample \\\n",
    "    .merge(algo_1,\n",
    "           how=\"left\",\n",
    "           left_on=[\"ds\", \"group_1\"],\n",
    "           right_on=[\"ds\", \"group_1\"]) \\\n",
    "    .merge(algo_2,\n",
    "           how=\"left\",\n",
    "           left_on=[\"ds\", \"group_1\"],\n",
    "           right_on=[\"ds\", \"group_1\"]) \\\n",
    "    .merge(algo_3,\n",
    "           how=\"left\",\n",
    "           left_on=[\"ds\", \"group_1\"],\n",
    "           right_on=[\"ds\", \"group_1\"]) \\\n",
    "    .merge(algo_4,\n",
    "           how=\"left\",\n",
    "           left_on=[\"ds\", \"group_1\"],\n",
    "           right_on=[\"ds\", \"group_1\"]) \\\n",
    "    .merge(algo_5,\n",
    "           how=\"left\",\n",
    "           left_on=[\"ds\", \"group_1\"],\n",
    "           right_on=[\"ds\", \"group_1\"])\n",
    "\n",
    "algo_joint"
   ],
   "id": "3b94442e7e616376",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           ds     group_1  algo_1_markup  algo_2_markup  algo_3_markup  \\\n",
       "0    20231008  group_1000           0.06           0.02           0.01   \n",
       "1    20231008  group_1001           0.04           0.06           0.04   \n",
       "2    20231008  group_1002           0.06           0.01           0.05   \n",
       "3    20231008  group_1003           0.05           0.00           0.06   \n",
       "4    20231008  group_1004           0.06           0.01           0.02   \n",
       "..        ...         ...            ...            ...            ...   \n",
       "541  20231021  group_1034           0.03           0.00           0.01   \n",
       "542  20231021  group_1035           0.05           0.04           0.06   \n",
       "543  20231021  group_1036           0.06           0.02           0.01   \n",
       "544  20231021  group_1037           0.03           0.05           0.01   \n",
       "545  20231021  group_1038           0.01           0.02           0.03   \n",
       "\n",
       "     algo_4_markup  algo_5_markup  \n",
       "0             0.02           0.05  \n",
       "1             0.02           0.00  \n",
       "2             0.01           0.05  \n",
       "3             0.06           0.00  \n",
       "4             0.03           0.05  \n",
       "..             ...            ...  \n",
       "541           0.04           0.05  \n",
       "542           0.04           0.03  \n",
       "543           0.05           0.01  \n",
       "544           0.06           0.04  \n",
       "545           0.01           0.03  \n",
       "\n",
       "[546 rows x 7 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>group_1</th>\n",
       "      <th>algo_1_markup</th>\n",
       "      <th>algo_2_markup</th>\n",
       "      <th>algo_3_markup</th>\n",
       "      <th>algo_4_markup</th>\n",
       "      <th>algo_5_markup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20231008</td>\n",
       "      <td>group_1000</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20231008</td>\n",
       "      <td>group_1001</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20231008</td>\n",
       "      <td>group_1002</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20231008</td>\n",
       "      <td>group_1003</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20231008</td>\n",
       "      <td>group_1004</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>20231021</td>\n",
       "      <td>group_1034</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>20231021</td>\n",
       "      <td>group_1035</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>20231021</td>\n",
       "      <td>group_1036</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>20231021</td>\n",
       "      <td>group_1037</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>20231021</td>\n",
       "      <td>group_1038</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>546 rows × 7 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T19:30:26.256676Z",
     "start_time": "2025-08-21T19:30:26.133677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Join A/B Test data and Algorithm's data\n",
    "ab_df_with_algo = ab_df \\\n",
    "    .merge(algo_joint,\n",
    "           how=\"left\",\n",
    "           left_on=[\"ds\", \"group_1\"],\n",
    "           right_on=[\"ds\", \"group_1\"])\n",
    "\n",
    "ab_df_with_algo"
   ],
   "id": "cd692a299bab5984",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           group_1      sku_id ab_test_id  markup   revenue  traffic  \\\n",
       "0       group_1000  sku_100000  ab_100000    0.01   2539.41     0.05   \n",
       "1       group_1001  sku_100001  ab_100001    0.02   6057.44     0.05   \n",
       "2       group_1002  sku_100002  ab_100002    0.01    541.35     0.05   \n",
       "3       group_1002  sku_100003  ab_100003    0.06    697.70     0.05   \n",
       "4       group_1001  sku_100004  ab_100004    0.01   1413.99     0.05   \n",
       "...            ...         ...        ...     ...       ...      ...   \n",
       "511808  group_1002  sku_101093  ab_100019    0.03    178.71     0.05   \n",
       "511809  group_1012  sku_101412  ab_100013    0.03     88.71     0.05   \n",
       "511810  group_1024  sku_103568  ab_100017    0.03     55.29     0.05   \n",
       "511811  group_1001  sku_100697  ab_100004    0.02   8885.78     0.05   \n",
       "511812  group_1017  sku_101067  ab_100001    0.06  17350.76     0.05   \n",
       "\n",
       "        orders_num        ds     margin  algo_1_markup  algo_2_markup  \\\n",
       "0              1.0  20231008    25.3941           0.06           0.02   \n",
       "1              3.0  20231008   121.1488           0.04           0.06   \n",
       "2              8.0  20231008     5.4135           0.06           0.01   \n",
       "3              0.0  20231008    41.8620           0.06           0.01   \n",
       "4              0.0  20231008    14.1399           0.04           0.06   \n",
       "...            ...       ...        ...            ...            ...   \n",
       "511808         2.0  20231021     5.3613           0.05           0.06   \n",
       "511809         2.0  20231021     2.6613           0.06           0.00   \n",
       "511810         1.0  20231021     1.6587           0.05           0.06   \n",
       "511811         1.0  20231021   177.7156           0.03           0.06   \n",
       "511812         9.0  20231021  1041.0456           0.04           0.03   \n",
       "\n",
       "        algo_3_markup  algo_4_markup  algo_5_markup  \n",
       "0                0.01           0.02           0.05  \n",
       "1                0.04           0.02           0.00  \n",
       "2                0.05           0.01           0.05  \n",
       "3                0.05           0.01           0.05  \n",
       "4                0.04           0.02           0.00  \n",
       "...               ...            ...            ...  \n",
       "511808           0.00           0.03           0.03  \n",
       "511809           0.04           0.00           0.01  \n",
       "511810           0.04           0.02           0.05  \n",
       "511811           0.03           0.00           0.05  \n",
       "511812           0.06           0.02           0.02  \n",
       "\n",
       "[511813 rows x 14 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_1</th>\n",
       "      <th>sku_id</th>\n",
       "      <th>ab_test_id</th>\n",
       "      <th>markup</th>\n",
       "      <th>revenue</th>\n",
       "      <th>traffic</th>\n",
       "      <th>orders_num</th>\n",
       "      <th>ds</th>\n",
       "      <th>margin</th>\n",
       "      <th>algo_1_markup</th>\n",
       "      <th>algo_2_markup</th>\n",
       "      <th>algo_3_markup</th>\n",
       "      <th>algo_4_markup</th>\n",
       "      <th>algo_5_markup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>group_1000</td>\n",
       "      <td>sku_100000</td>\n",
       "      <td>ab_100000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2539.41</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20231008</td>\n",
       "      <td>25.3941</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>group_1001</td>\n",
       "      <td>sku_100001</td>\n",
       "      <td>ab_100001</td>\n",
       "      <td>0.02</td>\n",
       "      <td>6057.44</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20231008</td>\n",
       "      <td>121.1488</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>group_1002</td>\n",
       "      <td>sku_100002</td>\n",
       "      <td>ab_100002</td>\n",
       "      <td>0.01</td>\n",
       "      <td>541.35</td>\n",
       "      <td>0.05</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20231008</td>\n",
       "      <td>5.4135</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>group_1002</td>\n",
       "      <td>sku_100003</td>\n",
       "      <td>ab_100003</td>\n",
       "      <td>0.06</td>\n",
       "      <td>697.70</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20231008</td>\n",
       "      <td>41.8620</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>group_1001</td>\n",
       "      <td>sku_100004</td>\n",
       "      <td>ab_100004</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1413.99</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20231008</td>\n",
       "      <td>14.1399</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511808</th>\n",
       "      <td>group_1002</td>\n",
       "      <td>sku_101093</td>\n",
       "      <td>ab_100019</td>\n",
       "      <td>0.03</td>\n",
       "      <td>178.71</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20231021</td>\n",
       "      <td>5.3613</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511809</th>\n",
       "      <td>group_1012</td>\n",
       "      <td>sku_101412</td>\n",
       "      <td>ab_100013</td>\n",
       "      <td>0.03</td>\n",
       "      <td>88.71</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20231021</td>\n",
       "      <td>2.6613</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511810</th>\n",
       "      <td>group_1024</td>\n",
       "      <td>sku_103568</td>\n",
       "      <td>ab_100017</td>\n",
       "      <td>0.03</td>\n",
       "      <td>55.29</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20231021</td>\n",
       "      <td>1.6587</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511811</th>\n",
       "      <td>group_1001</td>\n",
       "      <td>sku_100697</td>\n",
       "      <td>ab_100004</td>\n",
       "      <td>0.02</td>\n",
       "      <td>8885.78</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20231021</td>\n",
       "      <td>177.7156</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511812</th>\n",
       "      <td>group_1017</td>\n",
       "      <td>sku_101067</td>\n",
       "      <td>ab_100001</td>\n",
       "      <td>0.06</td>\n",
       "      <td>17350.76</td>\n",
       "      <td>0.05</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20231021</td>\n",
       "      <td>1041.0456</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>511813 rows × 14 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T19:30:26.414675Z",
     "start_time": "2025-08-21T19:30:26.308677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Group by \"ds\", \"group_1\", \"ab_test_id\"\n",
    "ab_df_joint = ab_df_with_algo \\\n",
    "    .groupby([\"ds\", \"group_1\", \"ab_test_id\"], as_index=False) \\\n",
    "    .agg(traffic = (\"traffic\", \"mean\"),\n",
    "         orders_num = (\"orders_num\", \"sum\"),\n",
    "         markup = (\"markup\", \"mean\"),\n",
    "         algo_1_markup = (\"algo_1_markup\", \"mean\"),\n",
    "         algo_2_markup = (\"algo_2_markup\", \"mean\"),\n",
    "         algo_3_markup = (\"algo_3_markup\", \"mean\"),\n",
    "         algo_4_markup = (\"algo_4_markup\", \"mean\"),\n",
    "         algo_5_markup = (\"algo_5_markup\", \"mean\")) \\\n",
    "    .assign(orders_num = lambda x: x[\"orders_num\"] / x[\"traffic\"]) \\\n",
    "    .round(2)\n",
    "\n",
    "# Group by and normalize\n",
    "ab_df_joint = ab_df_joint \\\n",
    "    .groupby([\"ds\", \"group_1\", \"markup\"], as_index=False) \\\n",
    "    .agg(orders_num = (\"orders_num\", \"mean\"),\n",
    "         markup = (\"markup\", \"mean\"),\n",
    "         algo_1_markup = (\"algo_1_markup\", \"mean\"),\n",
    "         algo_2_markup = (\"algo_2_markup\", \"mean\"),\n",
    "         algo_3_markup = (\"algo_3_markup\", \"mean\"),\n",
    "         algo_4_markup = (\"algo_4_markup\", \"mean\"),\n",
    "         algo_5_markup = (\"algo_5_markup\", \"mean\")) \\\n",
    "    .filter([\"group_1\", \"markup\",\n",
    "             \"algo_1_markup\", \"algo_2_markup\", \"algo_3_markup\", \"algo_4_markup\", \"algo_5_markup\",\n",
    "             \"orders_num\", \"ds\"]) \\\n",
    "    .round(2)"
   ],
   "id": "4ae244ef9d566a3e",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T19:30:26.491677Z",
     "start_time": "2025-08-21T19:30:26.463679Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the data\n",
    "ab_df_joint.to_csv(\"./data/homework_2_1.csv\", index=False)"
   ],
   "id": "9e5ff4ba963165b7",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## TASK 2",
   "id": "f9872a0ee5db2f98"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T19:30:26.536677Z",
     "start_time": "2025-08-21T19:30:26.506679Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Epsilon Greedy Algorithm\n",
    "class EpsilonGreedySum:\n",
    "    def __init__(\n",
    "        self,\n",
    "        epsilon: float = 0.005,\n",
    "        do_show_intersection: bool = True,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        epsilon - разница между наценками, которую считаем незначимой\n",
    "        do_show_intersection - показывать ли пересечение исторических и предсказанных наценок:\n",
    "        - если высокий процент, то BackTest'у можно доверять\n",
    "        - если низкий процент, то недостаточно данных для проведения BackTest'a\n",
    "        \"\"\"\n",
    "        self.epsilon = epsilon\n",
    "        self.do_show_intersection = do_show_intersection\n",
    "\n",
    "    def calculate_group_metrics(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        lvl: str,\n",
    "        prefix: str,\n",
    "        metrics: List[BackTestMetric],\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Считает предсказания по метрикам с учетом epsilon\n",
    "        Calculates predictions for given markup. The right algorithm's markup is defined as closest to real A/B test markup with +/- epsilon distance to it\n",
    "        \"\"\"\n",
    "\n",
    "        # Only those A/B test markups are left that are between corresponding Algorithm's Markup (+/- defined epsilon)\n",
    "        df_filtered = df[\n",
    "            df[\"markup\"].between(\n",
    "                df[f\"{prefix}_markup\"] - self.epsilon,\n",
    "                df[f\"{prefix}_markup\"] + self.epsilon,\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        # Get dictionary of metric and corresponding aggregation function (mean)\n",
    "        agg_functions = {metric: \"mean\" for metric in metrics}\n",
    "\n",
    "        # Group by date (ds), level (group_1) and algorithm's markup (algo_1_markup) and aggregate using the aggregations provided above\n",
    "        stats_df = (\n",
    "            df_filtered.groupby([\"ds\", lvl, f\"{prefix}_markup\"])\n",
    "            .agg(agg_functions)\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        # Rename the columns\n",
    "        stats_df = stats_df.rename(\n",
    "            columns={metric: f\"{prefix}_{metric}\" for metric in metrics}\n",
    "        )\n",
    "\n",
    "        # Round the numbers\n",
    "        stats_df = stats_df.round(2)\n",
    "\n",
    "        return stats_df\n",
    "\n",
    "    @staticmethod\n",
    "    def show_intersection(\n",
    "        lvl: str,\n",
    "        control_stats_df: pd.DataFrame,\n",
    "        test_stats_df: pd.DataFrame,\n",
    "        stats_df: pd.DataFrame,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Показывает пересечение исторических и предсказанных наценок:\n",
    "        - если высокий процент, то BackTest'у можно доверять\n",
    "        - если низкий процент, то недостаточно данных для проведения BackTest'a\n",
    "        \"\"\"\n",
    "        control_distinct_df = (\n",
    "            control_stats_df.groupby(\"ds\")[lvl].nunique().reset_index(name=\"control\")\n",
    "        )\n",
    "        test_distinct_df = (\n",
    "            test_stats_df.groupby(\"ds\")[lvl].nunique().reset_index(name=\"test\")\n",
    "        )\n",
    "        inter_distinct_df = (\n",
    "            stats_df.groupby(\"ds\")[lvl].nunique().reset_index(name=\"inter\")\n",
    "        )\n",
    "\n",
    "        distinct_df = pd.merge(\n",
    "            test_distinct_df, control_distinct_df, how=\"left\", on=[\"ds\"]\n",
    "        )\n",
    "        distinct_df = pd.merge(distinct_df, inter_distinct_df, how=\"left\", on=[\"ds\"])\n",
    "\n",
    "        distinct_df[\"inter / test\"] = distinct_df[\"inter\"] / distinct_df[\"test\"]\n",
    "        distinct_df[\"inter / control\"] = distinct_df[\"inter\"] / distinct_df[\"control\"]\n",
    "\n",
    "        logger.info(f\"Unique {lvl} intersection:\\n{distinct_df.to_markdown()}\")\n",
    "        mean_distinct_df = distinct_df.drop(columns=[\"ds\"]).mean().round(2)\n",
    "        logger.info(f\"Mean unique {lvl} intersection:\\n{mean_distinct_df.to_markdown()}\")\n",
    "\n",
    "    def calculate_groups_metrics(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        lvl: str,\n",
    "        metrics: List[BackTestMetric],\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        1) Считает для каждой группы предсказания по метрикам с учетом epsilon\n",
    "        2) Показывает пересечение исторических и предсказанных наценок\n",
    "        \"\"\"\n",
    "\n",
    "        # Gets predicitons for each algorithm's markup by considering real data from A/B test where those real markups are selected that are within +/- epsilon distance from algorithm's markup\n",
    "        df_01 = self.calculate_group_metrics(\n",
    "            df=df,\n",
    "            lvl=lvl,\n",
    "            prefix=\"algo_1\",\n",
    "            metrics=metrics,\n",
    "        )\n",
    "\n",
    "        df_02 = self.calculate_group_metrics(\n",
    "            df=df,\n",
    "            lvl=lvl,\n",
    "            prefix=\"algo_2\",\n",
    "            metrics=metrics,\n",
    "        )\n",
    "\n",
    "        df_03 = self.calculate_group_metrics(\n",
    "            df=df,\n",
    "            lvl=lvl,\n",
    "            prefix=\"algo_3\",\n",
    "            metrics=metrics,\n",
    "        )\n",
    "\n",
    "        df_04 = self.calculate_group_metrics(\n",
    "            df=df,\n",
    "            lvl=lvl,\n",
    "            prefix=\"algo_4\",\n",
    "            metrics=metrics,\n",
    "        )\n",
    "\n",
    "        df_05 = self.calculate_group_metrics(\n",
    "            df=df,\n",
    "            lvl=lvl,\n",
    "            prefix=\"algo_5\",\n",
    "            metrics=metrics,\n",
    "        )\n",
    "\n",
    "        # Get list of columns that are both present in TEST and CONTROL datasets\n",
    "        common_columns = list(\n",
    "            set(df_01.columns).intersection(set(df_02.columns))\n",
    "        )\n",
    "\n",
    "        # Join TEST and CONTROL datasets by the columns that are defined above\n",
    "        stats_df = df_01 \\\n",
    "            .merge(df_02,\n",
    "                   how=\"inner\",\n",
    "                   on=common_columns) \\\n",
    "            .merge(df_03,\n",
    "                   how=\"inner\",\n",
    "                   on=common_columns) \\\n",
    "            .merge(df_04,\n",
    "                   how=\"inner\",\n",
    "                   on=common_columns) \\\n",
    "            .merge(df_05,\n",
    "                   how=\"inner\",\n",
    "                   on=common_columns)\n",
    "\n",
    "        # IT'S NECESSARY TO DESCRIBE THIS PART\n",
    "        if self.do_show_intersection:\n",
    "            self.show_intersection(\n",
    "                lvl=lvl,\n",
    "                control_stats_df=df_01,\n",
    "                test_stats_df=df_02,\n",
    "                stats_df=stats_df,\n",
    "            )\n",
    "\n",
    "        return stats_df\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_statistics(df: pd.DataFrame, metrics: List[BackTestMetric]) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Считает значения метрик по дням для контрольной и тестовой группам\n",
    "        \"\"\"\n",
    "\n",
    "        # Create an empty dicitonary with \"algo\" and \"ds\" keys\n",
    "        result: Dict[str, Any] = {\n",
    "            \"algo\": [],\n",
    "            \"ds\": [],\n",
    "        }\n",
    "\n",
    "        # Update the dictionary with keys for each provided metric\n",
    "        result.update({metric: [] for metric in metrics})\n",
    "\n",
    "        # Define aggregation functions for each provided metric (CONTROL GROUP)\n",
    "        agg_functions = {f\"algo_1_{metric}\": \"sum\" for metric in metrics}\n",
    "\n",
    "        # Defina aggregation funcitons for each provided metric (TEST GROUP)\n",
    "        agg_functions.update({f\"algo_2_{metric}\": \"sum\" for metric in metrics})\n",
    "        agg_functions.update({f\"algo_3_{metric}\": \"sum\" for metric in metrics})\n",
    "        agg_functions.update({f\"algo_4_{metric}\": \"sum\" for metric in metrics})\n",
    "        agg_functions.update({f\"algo_5_{metric}\": \"sum\" for metric in metrics})\n",
    "\n",
    "        # Group by date (ds) and aggregate by functions defined above\n",
    "        stats_df = df.groupby(\"ds\").agg(agg_functions).reset_index()\n",
    "\n",
    "        # Calculate number of rows in \"stats_df\" dataframe (actually, it's number of unique dates in the dataset)\n",
    "        stats_rows_num = stats_df.shape[0]\n",
    "\n",
    "        # Iterate through different algorithms\n",
    "        for group in [\"algo_1\", \"algo_2\", \"algo_3\", \"algo_4\", \"algo_5\"]:\n",
    "\n",
    "            # Fill in \"algo\" key of \"result\" dictionary with name of algorithm\n",
    "            result[\"algo\"] += [group] * stats_rows_num\n",
    "\n",
    "            # Iterate trhough provided metrics\n",
    "            for metric in metrics:\n",
    "\n",
    "                # Store the metric results in \"result\" dictionary for given metric and group\n",
    "                result[metric] += stats_df[f\"{group}_{metric}\"].tolist()\n",
    "\n",
    "            # Store dates in \"result\" dictionary for given group\n",
    "            result[\"ds\"] += stats_df[\"ds\"].tolist()\n",
    "\n",
    "        # Convert the dictionary to dataframe\n",
    "        result_df = pd.DataFrame(data=result)\n",
    "\n",
    "        return result_df\n",
    "\n",
    "    def run(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        lvl: str,\n",
    "        metrics: List[BackTestMetric],\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Входная точка алгоритма BackTest'а на основе epsilon\n",
    "        \"\"\"\n",
    "\n",
    "        # For each date, group (item category) and algorithm's markup that is close to real A/B test markup by +/- epsilon distance, calculate mean value of metric of interest\n",
    "        stats_df = self.calculate_groups_metrics(df=df, lvl=lvl, metrics=metrics)\n",
    "\n",
    "        # For each date and algorithm, calculate the metric of interest\n",
    "        result_df = self.calculate_statistics(df=stats_df, metrics=metrics)\n",
    "\n",
    "        return result_df\n",
    "\n",
    "\n",
    "register = {\n",
    "    \"epsilon_greedy_sum\": EpsilonGreedySum,\n",
    "}\n",
    "\n",
    "\n",
    "def run_algo(\n",
    "    df: pd.DataFrame,\n",
    "    lvl: BackTestLevel,\n",
    "    algo: BackTestAlgo,\n",
    "    metrics: List[BackTestMetric],\n",
    "    algo_params: Optional[Dict[str, Any]] = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Входная точка алгоритма BackTest'а\n",
    "    \"\"\"\n",
    "\n",
    "    # Get class of provided algorithm\n",
    "    algo_obj = register.get(algo)\n",
    "\n",
    "    # If there's no class of algorithm, then display an error\n",
    "    if algo_obj is None:\n",
    "        raise ValueError(\n",
    "            f\"You should provide `algo` from the list: {BackTestAlgo.to_list()}\"\n",
    "        )\n",
    "\n",
    "    # Get algorithm parameters if defined. Otherwise, set an empty dictionary\n",
    "    algo_params = algo_params or {}\n",
    "\n",
    "    #\n",
    "    result_df = algo_obj(**algo_params).run(df=df, lvl=lvl, metrics=metrics)\n",
    "\n",
    "    return result_df"
   ],
   "id": "32f800c263737832",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T19:30:26.902678Z",
     "start_time": "2025-08-21T19:30:26.873678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Parameters of the algorithm\n",
    "ALGO_PARAMS = {\n",
    "    \"epsilon\": 0.01,\n",
    "    \"do_show_intersection\": False,\n",
    "}\n",
    "\n",
    "METRICS = [BackTestMetric.orders_num]\n",
    "LVL = BackTestLevel.group_1\n",
    "ALGO = BackTestAlgo.epsilon_greedy_sum\n",
    "\n",
    "# Run the algorithm\n",
    "result_df = run_algo(\n",
    "    df=ab_df_joint.copy(),\n",
    "    algo=ALGO,\n",
    "    lvl=LVL,\n",
    "    algo_params=ALGO_PARAMS,\n",
    "    metrics=METRICS\n",
    ")\n",
    "\n",
    "# Rename columns\n",
    "result_df.columns = [\"algo\", \"ds\", \"orders_num\"]\n",
    "\n",
    "# Save the results\n",
    "result_df.to_csv(\"./data/homework_2_2.csv\", index=False)"
   ],
   "id": "9bef9db0f41d0956",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## TASK 3",
   "id": "e1bb618185fc956b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T19:30:27.060708Z",
     "start_time": "2025-08-21T19:30:27.050710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Arrange algorithms\n",
    "result_df \\\n",
    "    .groupby([\"algo\"], as_index=False) \\\n",
    "    .agg(orders_num = (\"orders_num\", \"sum\")) \\\n",
    "    .sort_values(\"orders_num\", ascending=False)"
   ],
   "id": "c1a4ee987bf8c70e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     algo  orders_num\n",
       "4  algo_5  4282026.49\n",
       "0  algo_1  4262385.09\n",
       "2  algo_3  4227637.97\n",
       "1  algo_2  4215161.79\n",
       "3  algo_4  4194876.17"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algo</th>\n",
       "      <th>orders_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>algo_5</td>\n",
       "      <td>4282026.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>algo_1</td>\n",
       "      <td>4262385.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>algo_3</td>\n",
       "      <td>4227637.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>algo_2</td>\n",
       "      <td>4215161.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>algo_4</td>\n",
       "      <td>4194876.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
